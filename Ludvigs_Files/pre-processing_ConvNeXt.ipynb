{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('running on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_IMG_SIZE = 48\n",
    "IMG_SIZE = 72\n",
    "\n",
    "CLASSES = ['neutral', 'happy', 'surprised', 'sad', 'angry'] #, 'disgusted', 'afraid'\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 35887\n",
      "after removing images with unknown/unsure classification: 26811\n"
     ]
    }
   ],
   "source": [
    "df_fer = pd.read_csv('../data/fer2013.csv').iloc[:, 1:]\n",
    "df_ferplus = pd.read_csv('../data/ferplus2013.csv').iloc[:, [2, 3, 4, 5, 6]]\n",
    "df = df_fer.join(df_ferplus)\n",
    "# df.head(15)\n",
    "\n",
    "df['emotion'] = df.iloc[:, 2:].idxmax(axis=1).tolist()\n",
    "df = df.replace(dict(zip(pd.Series(CLASSES),pd.Series(CLASSES).index)))\n",
    "# df.head(15)\n",
    "\n",
    "print('number of images:', df.shape[0])\n",
    "df = df[(df.iloc[:, 2:-1].max(axis=1) > 5)]\n",
    "print('after removing images with unknown/unsure classification:', df.shape[0])\n",
    "# df.head(15)\n",
    "\n",
    "df = df.iloc[:, [0, 1, -1]]\n",
    "# df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "images_np = np.array(df['pixels'])\n",
    "label_np = np.array(df['emotion'])\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    b = bytes(int(p) for p in images_np[i].split())\n",
    "    img = Image.frombuffer('L', (SOURCE_IMG_SIZE, SOURCE_IMG_SIZE), b)\n",
    "    images.append(transform(img))\n",
    "    labels.append(label_np[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mclass              #images\u001b[0m\n",
      "neutral               9494\n",
      "happy                 8802\n",
      "surprised             3461\n",
      "sad                   2958\n",
      "angry                 2096\n"
     ]
    }
   ],
   "source": [
    "label_counts = [0]*NUM_CLASSES\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label_counts[labels[i]] += 1\n",
    "\n",
    "print('\\033[4m{: <15} {: >10}\\033[0m'.format('class', '#images'))\n",
    "for i in range(NUM_CLASSES):\n",
    "    print('{: <15} {: >10}'.format(CLASSES[i], label_counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 21448 (80.0%)\n",
      "test length: 5363 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "train_split_pct = 0.8\n",
    "train_len = int(len(labels) * train_split_pct)\n",
    "\n",
    "train_images = images[:train_len]\n",
    "train_labels = labels[:train_len]\n",
    "test_images = images[train_len:]\n",
    "test_labels = labels[train_len:]\n",
    "\n",
    "print(f'train length: {len(train_labels)} ({len(train_labels)*100/len(labels):.1f}%)')\n",
    "print(f'test length: {len(test_labels)} ({len(test_labels)*100/len(labels):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_loader():\n",
      "  class weights: [ 2.848  3.015  7.771  8.963 12.991] \n",
      "\n",
      "get_loader():\n",
      "  class weights: [ 2.732  3.175  7.65   9.492 12.052] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, labels):      \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_images, train_labels)\n",
    "test_dataset = CustomDataset(test_images, test_labels)\n",
    "\n",
    "\n",
    "def get_loader(dataset):\n",
    "    print('get_loader():')\n",
    "\n",
    "    label_counts = [0]*NUM_CLASSES\n",
    "    for i in range(len(dataset.labels)):\n",
    "        label_counts[dataset.labels[i]] += 1\n",
    "\n",
    "    class_weights = pow(np.array(label_counts) / sum(label_counts), -1)\n",
    "    print('  class weights:', class_weights.round(3), '\\n')\n",
    "\n",
    "    sample_weights = [0]*len(dataset)\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        sample_weights[idx] = class_weights[label]\n",
    "\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return DataLoader(dataset, BATCH_SIZE, sampler=sampler, shuffle=False)\n",
    "\n",
    "\n",
    "train_loader = get_loader(train_dataset)\n",
    "test_loader = get_loader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# ConvNeXt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision._internally_replaced_utils import load_state_dict_from_url\n",
    "from torchvision.ops.misc import ConvNormActivation\n",
    "from torchvision.ops.stochastic_depth import StochasticDepth\n",
    "from torchvision.utils import _log_api_usage_once\n",
    "\n",
    "# Batch size during training, remember to change the global one as well\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "# Number of training epochs. 75 = 0.53\n",
    "num_epochs = 100\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'happy', 'surprised', 'sad', 'angry']\n"
     ]
    }
   ],
   "source": [
    "# Function for displaying predictions for a few images, in this case 6.\n",
    "#print(test_set[0])\n",
    "\n",
    "class_names = CLASSES\n",
    "print(class_names)\n",
    "\n",
    "def visualize_expression_model(model, num_images=4):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                plt.imshow(inputs.cpu().data[j].permute(1, 2, 0), cmap=\"gray\")\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expression_model(model, data, criterion, optimizer):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    model.train()   # Set model to train mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in data:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # zero the parameter gradients, and use backpropagatation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "    print('train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_expression_model(model, data, criterion):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in data:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(test_dataset)\n",
    "\n",
    "    print('test Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm2d(nn.LayerNorm):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Permute(nn.Module):\n",
    "    def __init__(self, dims: List[int]):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.permute(x, self.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNBlock(nn.Module):\n",
    "    def __init__(self, dim, layer_scale: float, stochastic_depth_prob: float, norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.LayerNorm, eps=1e-6)\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim, bias=True),\n",
    "            Permute([0, 2, 3, 1]),\n",
    "            norm_layer(dim),\n",
    "            nn.Linear(in_features=dim, out_features=4 * dim, bias=True),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=4 * dim, out_features=dim, bias=True),\n",
    "            Permute([0, 3, 1, 2]),\n",
    "        )\n",
    "        self.layer_scale = nn.Parameter(torch.ones(dim, 1, 1) * layer_scale)\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.layer_scale * self.block(input)\n",
    "        result = self.stochastic_depth(result)\n",
    "        result += input\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNBlockConfig:\n",
    "    # Stores information listed at Section 3 of the ConvNeXt paper\n",
    "    def __init__(self, input_channels: 1, out_channels: 5, num_layers: int) -> None:\n",
    "        self.input_channels = input_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        s = self.__class__.__name__ + \"(\"\n",
    "        s += \"input_channels={input_channels}\"\n",
    "        s += \", out_channels={out_channels}\"\n",
    "        s += \", num_layers={num_layers}\"\n",
    "        s += \")\"\n",
    "        return s.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_setting: List[CNBlockConfig],\n",
    "        stochastic_depth_prob: float = 0.0,\n",
    "        layer_scale: float = 1e-6,\n",
    "        num_classes: int = NUM_CLASSES,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "\n",
    "        if not block_setting:\n",
    "            raise ValueError(\"The block_setting should not be empty\")\n",
    "        elif not (isinstance(block_setting, Sequence) and all([isinstance(s, CNBlockConfig) for s in block_setting])):\n",
    "            raise TypeError(\"The block_setting should be List[CNBlockConfig]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = CNBlock\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(LayerNorm2d, eps=1e-6)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # Stem\n",
    "        firstconv_output_channels = block_setting[0].input_channels\n",
    "        layers.append(\n",
    "            ConvNormActivation(1, firstconv_output_channels, kernel_size=4, stride=4, padding=0, norm_layer=norm_layer, activation_layer=None, bias=True) # Changed to 1 channel\n",
    "        )\n",
    "\n",
    "        total_stage_blocks = sum(cnf.num_layers for cnf in block_setting)\n",
    "        stage_block_id = 0\n",
    "        for cnf in block_setting:\n",
    "            # Bottlenecks\n",
    "            stage: List[nn.Module] = []\n",
    "            for _ in range(cnf.num_layers):\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = stochastic_depth_prob * stage_block_id / (total_stage_blocks - 1.0)\n",
    "                stage.append(block(cnf.input_channels, layer_scale, sd_prob))\n",
    "                stage_block_id += 1\n",
    "            layers.append(nn.Sequential(*stage))\n",
    "            if cnf.out_channels is not None:\n",
    "                # Downsampling\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        norm_layer(cnf.input_channels),\n",
    "                        nn.Conv2d(cnf.input_channels, cnf.out_channels, kernel_size=2, stride=2),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        lastblock = block_setting[-1]\n",
    "        lastconv_output_channels = (\n",
    "            lastblock.out_channels if lastblock.out_channels is not None else lastblock.input_channels\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            norm_layer(lastconv_output_channels), nn.Flatten(1), nn.Linear(lastconv_output_channels, num_classes)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny block size, other alternatives are available: tiny, small, base, and large. https://pytorch.org/vision/0.12/_modules/torchvision/models/convnext.html\n",
    "\n",
    "# block_setting = [ # tiny\n",
    "#         CNBlockConfig(96, 192, 3),\n",
    "#         CNBlockConfig(192, 384, 3),\n",
    "#         CNBlockConfig(384, 768, 9),\n",
    "#         CNBlockConfig(768, None, 3),\n",
    "#     ]\n",
    "# model = ConvNeXt(block_setting, stochastic_depth_prob=0.1).to(device)\n",
    "\n",
    "block_setting = [ # base\n",
    "        CNBlockConfig(128, 256, 3),\n",
    "        CNBlockConfig(256, 512, 3),\n",
    "        CNBlockConfig(512, 1024, 27),\n",
    "        CNBlockConfig(1024, None, 3),\n",
    "    ]\n",
    "model = ConvNeXt(block_setting, stochastic_depth_prob=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_model = model\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(expression_model.parameters(), lr=lr, momentum = 0.9)\n",
    "#optimizer = torch.optim.Adam(expression_model.parameters(), lr=lr)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 1 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.000001) #0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "train Loss: 0.0506 Acc: 0.2395\n",
      "test Loss: 0.0495 Acc: 0.2465\n",
      "Epoch 2/100\n",
      "\n",
      "train Loss: 0.0501 Acc: 0.2508\n",
      "test Loss: 0.0499 Acc: 0.2407\n",
      "Epoch 3/100\n",
      "\n",
      "train Loss: 0.0496 Acc: 0.2653\n",
      "test Loss: 0.0490 Acc: 0.2760\n",
      "Epoch 4/100\n",
      "\n",
      "train Loss: 0.0493 Acc: 0.2766\n",
      "test Loss: 0.0487 Acc: 0.2959\n",
      "Epoch 5/100\n",
      "\n",
      "train Loss: 0.0486 Acc: 0.2957\n",
      "test Loss: 0.0502 Acc: 0.2808\n",
      "Epoch 6/100\n",
      "\n",
      "train Loss: 0.0478 Acc: 0.3217\n",
      "test Loss: 0.0477 Acc: 0.3285\n",
      "Epoch 7/100\n",
      "\n",
      "train Loss: 0.0473 Acc: 0.3298\n",
      "test Loss: 0.0482 Acc: 0.3246\n",
      "Epoch 8/100\n",
      "\n",
      "train Loss: 0.0469 Acc: 0.3433\n",
      "test Loss: 0.0485 Acc: 0.3028\n",
      "Epoch 9/100\n",
      "\n",
      "train Loss: 0.0462 Acc: 0.3592\n",
      "test Loss: 0.0465 Acc: 0.3541\n",
      "Epoch 10/100\n",
      "\n",
      "train Loss: 0.0460 Acc: 0.3607\n",
      "test Loss: 0.0465 Acc: 0.3409\n",
      "Epoch 11/100\n",
      "\n",
      "train Loss: 0.0456 Acc: 0.3690\n",
      "test Loss: 0.0458 Acc: 0.3504\n",
      "Epoch 12/100\n",
      "\n",
      "train Loss: 0.0456 Acc: 0.3721\n",
      "test Loss: 0.0473 Acc: 0.3444\n",
      "Epoch 13/100\n",
      "\n",
      "train Loss: 0.0452 Acc: 0.3758\n",
      "test Loss: 0.0457 Acc: 0.3651\n",
      "Epoch 14/100\n",
      "\n",
      "train Loss: 0.0452 Acc: 0.3775\n",
      "test Loss: 0.0465 Acc: 0.3504\n",
      "Epoch 15/100\n",
      "\n",
      "train Loss: 0.0451 Acc: 0.3802\n",
      "test Loss: 0.0468 Acc: 0.3606\n",
      "Epoch 16/100\n",
      "\n",
      "train Loss: 0.0448 Acc: 0.3855\n",
      "test Loss: 0.0474 Acc: 0.3511\n",
      "Epoch 17/100\n",
      "\n",
      "train Loss: 0.0448 Acc: 0.3826\n",
      "test Loss: 0.0461 Acc: 0.3522\n",
      "Epoch 18/100\n",
      "\n",
      "train Loss: 0.0446 Acc: 0.3879\n",
      "test Loss: 0.0457 Acc: 0.3707\n",
      "Epoch 19/100\n",
      "\n",
      "train Loss: 0.0447 Acc: 0.3903\n",
      "test Loss: 0.0451 Acc: 0.3880\n",
      "Epoch 20/100\n",
      "\n",
      "train Loss: 0.0442 Acc: 0.3984\n",
      "test Loss: 0.0467 Acc: 0.3608\n",
      "Epoch 21/100\n",
      "\n",
      "train Loss: 0.0441 Acc: 0.3960\n",
      "test Loss: 0.0452 Acc: 0.3826\n",
      "Epoch 22/100\n",
      "\n",
      "train Loss: 0.0439 Acc: 0.4001\n",
      "test Loss: 0.0453 Acc: 0.3802\n",
      "Epoch 23/100\n",
      "\n",
      "train Loss: 0.0437 Acc: 0.4061\n",
      "test Loss: 0.0451 Acc: 0.3856\n",
      "Epoch 24/100\n",
      "\n",
      "train Loss: 0.0439 Acc: 0.3988\n",
      "test Loss: 0.0454 Acc: 0.3774\n",
      "Epoch 25/100\n",
      "\n",
      "train Loss: 0.0438 Acc: 0.4077\n",
      "test Loss: 0.0452 Acc: 0.3783\n",
      "Epoch 26/100\n",
      "\n",
      "train Loss: 0.0437 Acc: 0.4043\n",
      "test Loss: 0.0446 Acc: 0.4000\n",
      "Epoch 27/100\n",
      "\n",
      "train Loss: 0.0435 Acc: 0.4118\n",
      "test Loss: 0.0444 Acc: 0.3940\n",
      "Epoch 28/100\n",
      "\n",
      "train Loss: 0.0434 Acc: 0.4084\n",
      "test Loss: 0.0454 Acc: 0.3923\n",
      "Epoch 29/100\n",
      "\n",
      "train Loss: 0.0430 Acc: 0.4161\n",
      "test Loss: 0.0467 Acc: 0.3808\n",
      "Epoch 30/100\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8340/1657059545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_expression_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpression_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest_expression_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpression_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#scheduler.step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8340/309117958.py\u001b[0m in \u001b[0;36mtrain_expression_model\u001b[1;34m(model, data, criterion, optimizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# zero the parameter gradients, and use backpropagatation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ludvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ludvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, (num_epochs+1)):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print()\n",
    "    train_expression_model(expression_model, train_loader, loss_fn, optimizer)\n",
    "    test_expression_model(expression_model, test_loader, loss_fn)\n",
    "    #scheduler.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End of ConvNeXt model\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = [0]*NUM_CLASSES\n",
    "samples_test = [0]*NUM_CLASSES\n",
    "\n",
    "for idx, (images, labels) in enumerate(train_loader):\n",
    "    for i in range(len(images)):\n",
    "        samples_train[labels[i].item()] += 1\n",
    "\n",
    "for idx, (images, labels) in enumerate(test_loader):\n",
    "    for i in range(len(images)):\n",
    "        samples_test[labels[i].item()] += 1\n",
    "\n",
    "\n",
    "print('\\033[4m{: <15} {: >15} {: >20}\\033[0m'.format('class', '#samples (train)', '#samples (test)'))\n",
    "for i in range(NUM_CLASSES):\n",
    "    print('{: <15} {: >15} {: >20}'.format(CLASSES[i], samples_train[i], samples_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(dataset, title='', num_images=(3,6), rand=True):\n",
    "\n",
    "    plt.figure(figsize=(num_images[1]*1.5, num_images[0]*2)); \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "\n",
    "    for i in range(num_images[0]):\n",
    "        for j in range(num_images[1]):\n",
    "            \n",
    "            c = num_images[1]*i+(j+1)\n",
    "\n",
    "            if not rand:\n",
    "                idx = c\n",
    "            else:\n",
    "                idx = random.randint(0, len(dataset)-1)\n",
    "\n",
    "            plt.subplot(num_images[0], num_images[1], c); plt.axis('off'); plt.title(CLASSES[dataset[idx][1]])\n",
    "            plt.imshow(dataset[idx][0].permute(1,2,0), cmap='gray')\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "imshow(train_dataset, 'Example images from the train dataset')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "462459bc3e617147c8cffc282d893ee434b18ff4bde70f08c233dfc73bb28fd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
