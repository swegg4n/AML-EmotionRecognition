{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader, Dataset\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('running on:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_IMG_SIZE = 48\n",
    "IMG_SIZE = 96\n",
    "\n",
    "CLASSES = ['neutral', 'happy', 'surprised', 'sad', 'angry'] #, 'disgusted', 'afraid'\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 35887\n",
      "after removing images with unknown/unsure classification: 26811\n"
     ]
    }
   ],
   "source": [
    "df_fer = pd.read_csv('../data/fer2013.csv').iloc[:, 1:]\n",
    "df_ferplus = pd.read_csv('../data/ferplus2013.csv').iloc[:, [2, 3, 4, 5, 6]]\n",
    "df = df_fer.join(df_ferplus)\n",
    "# df.head(15)\n",
    "\n",
    "df['emotion'] = df.iloc[:, 2:].idxmax(axis=1).tolist()\n",
    "df = df.replace(dict(zip(pd.Series(CLASSES),pd.Series(CLASSES).index)))\n",
    "# df.head(15)\n",
    "\n",
    "print('number of images:', df.shape[0])\n",
    "df = df[(df.iloc[:, 2:-1].max(axis=1) > 5)]\n",
    "print('after removing images with unknown/unsure classification:', df.shape[0])\n",
    "# df.head(15)\n",
    "\n",
    "df = df.iloc[:, [0, 1, -1]]\n",
    "# df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485), (0.229)),\n",
    "])\n",
    "\n",
    "images_np = np.array(df['pixels'])\n",
    "label_np = np.array(df['emotion'])\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    b = bytes(int(p) for p in images_np[i].split())\n",
    "    img = Image.frombuffer('L', (SOURCE_IMG_SIZE, SOURCE_IMG_SIZE), b)\n",
    "    images.append(transform(img))\n",
    "    labels.append(label_np[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mclass              #images\u001b[0m\n",
      "neutral               9494\n",
      "happy                 8802\n",
      "surprised             3461\n",
      "sad                   2958\n",
      "angry                 2096\n"
     ]
    }
   ],
   "source": [
    "label_counts = [0]*NUM_CLASSES\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label_counts[labels[i]] += 1\n",
    "\n",
    "print('\\033[4m{: <15} {: >10}\\033[0m'.format('class', '#images'))\n",
    "for i in range(NUM_CLASSES):\n",
    "    print('{: <15} {: >10}'.format(CLASSES[i], label_counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length: 21448 (80.0%)\n",
      "test length: 5363 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "train_split_pct = 0.8\n",
    "train_len = int(len(labels) * train_split_pct)\n",
    "\n",
    "train_images = images[:train_len]\n",
    "train_labels = labels[:train_len]\n",
    "test_images = images[train_len:]\n",
    "test_labels = labels[train_len:]\n",
    "\n",
    "print(f'train length: {len(train_labels)} ({len(train_labels)*100/len(labels):.1f}%)')\n",
    "print(f'test length: {len(test_labels)} ({len(test_labels)*100/len(labels):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_loader():\n",
      "  class weights: [ 2.848  3.015  7.771  8.963 12.991] \n",
      "\n",
      "get_loader():\n",
      "  class weights: [ 2.732  3.175  7.65   9.492 12.052] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, labels):      \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_images, train_labels)\n",
    "test_dataset = CustomDataset(test_images, test_labels)\n",
    "\n",
    "\n",
    "def get_loader(dataset):\n",
    "    print('get_loader():')\n",
    "\n",
    "    label_counts = [0]*NUM_CLASSES\n",
    "    for i in range(len(dataset.labels)):\n",
    "        label_counts[dataset.labels[i]] += 1\n",
    "\n",
    "    class_weights = pow(np.array(label_counts) / sum(label_counts), -1)\n",
    "    print('  class weights:', class_weights.round(3), '\\n')\n",
    "\n",
    "    sample_weights = [0]*len(dataset)\n",
    "    for idx, (image, label) in enumerate(dataset):\n",
    "        sample_weights[idx] = class_weights[label]\n",
    "\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return DataLoader(dataset, BATCH_SIZE, sampler=sampler, shuffle=False)\n",
    "\n",
    "\n",
    "train_loader = get_loader(train_dataset)\n",
    "test_loader = get_loader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# VGG (Visual Geometry Group) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "from torchvision.utils import _log_api_usage_once\n",
    "\n",
    "# Batch size during training, remember to change the global one as well\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 75\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'happy', 'surprised', 'sad', 'angry']\n"
     ]
    }
   ],
   "source": [
    "# Function for displaying predictions for a few images, in this case 6.\n",
    "#print(test_set[0])\n",
    "\n",
    "class_names = CLASSES\n",
    "print(class_names)\n",
    "\n",
    "def visualize_expression_model(model, num_images=4):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                plt.imshow(inputs.cpu().data[j].permute(1, 2, 0), cmap=\"gray\")\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expression_model(model, data, criterion, optimizer):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    model.train()   # Set model to train mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in data:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # zero the parameter gradients, and use backpropagatation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "    print('train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_expression_model(model, data, criterion):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, labels in data:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(test_dataset)\n",
    "\n",
    "    print('test Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fire(nn.Module):\n",
    "    def __init__(self, inplanes: int, squeeze_planes: int, expand1x1_planes: int, expand3x3_planes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat(\n",
    "            [self.expand1x1_activation(self.expand1x1(x)), self.expand3x3_activation(self.expand3x3(x))], 1\n",
    "        )\n",
    "\n",
    "\n",
    "class Facial_Expression_Network_VGG(nn.Module):\n",
    "    def __init__(self, version: str = \"1_1\", num_classes: int = NUM_CLASSES, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "        self.num_classes = num_classes\n",
    "        if version == \"1_0\": # train 96, test 78    (%)\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(1, 96, kernel_size=3, stride=1), # Changed from 3 channels to 1\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(96, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        elif version == \"1_1\": # train 98, test 78  (%), 12 min\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(1, 64, kernel_size=3, stride=2), # Changed from 3 channels to 1\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(64, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        else:\n",
    "            # FIXME: Is this needed? SqueezeNet should only be called from the\n",
    "            # FIXME: squeezenet1_x() functions\n",
    "            # FIXME: This checking is not done for the other models\n",
    "            raise ValueError(f\"Unsupported SqueezeNet version {version}: 1_0 or 1_1 expected\")\n",
    "\n",
    "        # Final convolution is initialized differently from the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout), final_conv, \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is final_conv:\n",
    "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "\n",
    "\n",
    "# def _squeezenet(version: str, pretrained: bool, progress: bool, **kwargs: Any) -> Facial_Expression_Network:\n",
    "#     model = Facial_Expression_Network(version, **kwargs)\n",
    "#     if pretrained:\n",
    "#         arch = \"squeezenet\" + version\n",
    "#         state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n",
    "#         model.load_state_dict(state_dict)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_model = Facial_Expression_Network_VGG().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(expression_model.parameters(), lr=lr, momentum = 0.9)\n",
    "#optimizer = torch.optim.Adam(expression_model.parameters(), lr=lr)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 1 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ludvi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0503 Acc: 0.2102\n",
      "test Loss: 0.0502 Acc: 0.2107\n",
      "Epoch 2/75\n",
      "\n",
      "train Loss: 0.0498 Acc: 0.2526\n",
      "test Loss: 0.0493 Acc: 0.2965\n",
      "Epoch 3/75\n",
      "\n",
      "train Loss: 0.0491 Acc: 0.2758\n",
      "test Loss: 0.0485 Acc: 0.3051\n",
      "Epoch 4/75\n",
      "\n",
      "train Loss: 0.0483 Acc: 0.2935\n",
      "test Loss: 0.0476 Acc: 0.3008\n",
      "Epoch 5/75\n",
      "\n",
      "train Loss: 0.0472 Acc: 0.3242\n",
      "test Loss: 0.0468 Acc: 0.3175\n",
      "Epoch 6/75\n",
      "\n",
      "train Loss: 0.0462 Acc: 0.3434\n",
      "test Loss: 0.0454 Acc: 0.3606\n",
      "Epoch 7/75\n",
      "\n",
      "train Loss: 0.0453 Acc: 0.3612\n",
      "test Loss: 0.0451 Acc: 0.3601\n",
      "Epoch 8/75\n",
      "\n",
      "train Loss: 0.0445 Acc: 0.3724\n",
      "test Loss: 0.0452 Acc: 0.3696\n",
      "Epoch 9/75\n",
      "\n",
      "train Loss: 0.0438 Acc: 0.3857\n",
      "test Loss: 0.0425 Acc: 0.4158\n",
      "Epoch 10/75\n",
      "\n",
      "train Loss: 0.0429 Acc: 0.4042\n",
      "test Loss: 0.0437 Acc: 0.3936\n",
      "Epoch 11/75\n",
      "\n",
      "train Loss: 0.0421 Acc: 0.4155\n",
      "test Loss: 0.0407 Acc: 0.4520\n",
      "Epoch 12/75\n",
      "\n",
      "train Loss: 0.0414 Acc: 0.4356\n",
      "test Loss: 0.0405 Acc: 0.4604\n",
      "Epoch 13/75\n",
      "\n",
      "train Loss: 0.0411 Acc: 0.4372\n",
      "test Loss: 0.0397 Acc: 0.4628\n",
      "Epoch 14/75\n",
      "\n",
      "train Loss: 0.0400 Acc: 0.4582\n",
      "test Loss: 0.0384 Acc: 0.4861\n",
      "Epoch 15/75\n",
      "\n",
      "train Loss: 0.0390 Acc: 0.4818\n",
      "test Loss: 0.0385 Acc: 0.5053\n",
      "Epoch 16/75\n",
      "\n",
      "train Loss: 0.0378 Acc: 0.4987\n",
      "test Loss: 0.0371 Acc: 0.5085\n",
      "Epoch 17/75\n",
      "\n",
      "train Loss: 0.0371 Acc: 0.5070\n",
      "test Loss: 0.0378 Acc: 0.4995\n",
      "Epoch 18/75\n",
      "\n",
      "train Loss: 0.0357 Acc: 0.5321\n",
      "test Loss: 0.0359 Acc: 0.5286\n",
      "Epoch 19/75\n",
      "\n",
      "train Loss: 0.0348 Acc: 0.5466\n",
      "test Loss: 0.0351 Acc: 0.5443\n",
      "Epoch 20/75\n",
      "\n",
      "train Loss: 0.0337 Acc: 0.5613\n",
      "test Loss: 0.0354 Acc: 0.5558\n",
      "Epoch 21/75\n",
      "\n",
      "train Loss: 0.0327 Acc: 0.5751\n",
      "test Loss: 0.0327 Acc: 0.5816\n",
      "Epoch 22/75\n",
      "\n",
      "train Loss: 0.0323 Acc: 0.5850\n",
      "test Loss: 0.0320 Acc: 0.5950\n",
      "Epoch 23/75\n",
      "\n",
      "train Loss: 0.0312 Acc: 0.6000\n",
      "test Loss: 0.0336 Acc: 0.5780\n",
      "Epoch 24/75\n",
      "\n",
      "train Loss: 0.0307 Acc: 0.6070\n",
      "test Loss: 0.0312 Acc: 0.6066\n",
      "Epoch 25/75\n",
      "\n",
      "train Loss: 0.0297 Acc: 0.6194\n",
      "test Loss: 0.0309 Acc: 0.6043\n",
      "Epoch 26/75\n",
      "\n",
      "train Loss: 0.0289 Acc: 0.6343\n",
      "test Loss: 0.0312 Acc: 0.6034\n",
      "Epoch 27/75\n",
      "\n",
      "train Loss: 0.0288 Acc: 0.6412\n",
      "test Loss: 0.0290 Acc: 0.6517\n",
      "Epoch 28/75\n",
      "\n",
      "train Loss: 0.0278 Acc: 0.6526\n",
      "test Loss: 0.0282 Acc: 0.6494\n",
      "Epoch 29/75\n",
      "\n",
      "train Loss: 0.0275 Acc: 0.6554\n",
      "test Loss: 0.0279 Acc: 0.6504\n",
      "Epoch 30/75\n",
      "\n",
      "train Loss: 0.0267 Acc: 0.6615\n",
      "test Loss: 0.0293 Acc: 0.6315\n",
      "Epoch 31/75\n",
      "\n",
      "train Loss: 0.0265 Acc: 0.6679\n",
      "test Loss: 0.0288 Acc: 0.6263\n",
      "Epoch 32/75\n",
      "\n",
      "train Loss: 0.0262 Acc: 0.6727\n",
      "test Loss: 0.0271 Acc: 0.6575\n",
      "Epoch 33/75\n",
      "\n",
      "train Loss: 0.0251 Acc: 0.6888\n",
      "test Loss: 0.0303 Acc: 0.6427\n",
      "Epoch 34/75\n",
      "\n",
      "train Loss: 0.0248 Acc: 0.6878\n",
      "test Loss: 0.0274 Acc: 0.6565\n",
      "Epoch 35/75\n",
      "\n",
      "train Loss: 0.0248 Acc: 0.6885\n",
      "test Loss: 0.0275 Acc: 0.6595\n",
      "Epoch 36/75\n",
      "\n",
      "train Loss: 0.0241 Acc: 0.6993\n",
      "test Loss: 0.0258 Acc: 0.6864\n",
      "Epoch 37/75\n",
      "\n",
      "train Loss: 0.0235 Acc: 0.7092\n",
      "test Loss: 0.0259 Acc: 0.6804\n",
      "Epoch 38/75\n",
      "\n",
      "train Loss: 0.0232 Acc: 0.7140\n",
      "test Loss: 0.0262 Acc: 0.6739\n",
      "Epoch 39/75\n",
      "\n",
      "train Loss: 0.0226 Acc: 0.7206\n",
      "test Loss: 0.0253 Acc: 0.6942\n",
      "Epoch 40/75\n",
      "\n",
      "train Loss: 0.0220 Acc: 0.7272\n",
      "test Loss: 0.0275 Acc: 0.6789\n",
      "Epoch 41/75\n",
      "\n",
      "train Loss: 0.0219 Acc: 0.7309\n",
      "test Loss: 0.0253 Acc: 0.6903\n",
      "Epoch 42/75\n",
      "\n",
      "train Loss: 0.0213 Acc: 0.7384\n",
      "test Loss: 0.0253 Acc: 0.6985\n",
      "Epoch 43/75\n",
      "\n",
      "train Loss: 0.0213 Acc: 0.7402\n",
      "test Loss: 0.0252 Acc: 0.7030\n",
      "Epoch 44/75\n",
      "\n",
      "train Loss: 0.0208 Acc: 0.7421\n",
      "test Loss: 0.0272 Acc: 0.6707\n",
      "Epoch 45/75\n",
      "\n",
      "train Loss: 0.0205 Acc: 0.7469\n",
      "test Loss: 0.0248 Acc: 0.6977\n",
      "Epoch 46/75\n",
      "\n",
      "train Loss: 0.0199 Acc: 0.7572\n",
      "test Loss: 0.0251 Acc: 0.7011\n",
      "Epoch 47/75\n",
      "\n",
      "train Loss: 0.0195 Acc: 0.7624\n",
      "test Loss: 0.0252 Acc: 0.6938\n",
      "Epoch 48/75\n",
      "\n",
      "train Loss: 0.0197 Acc: 0.7597\n",
      "test Loss: 0.0249 Acc: 0.7076\n",
      "Epoch 49/75\n",
      "\n",
      "train Loss: 0.0191 Acc: 0.7661\n",
      "test Loss: 0.0245 Acc: 0.7078\n",
      "Epoch 50/75\n",
      "\n",
      "train Loss: 0.0186 Acc: 0.7715\n",
      "test Loss: 0.0264 Acc: 0.6901\n",
      "Epoch 51/75\n",
      "\n",
      "train Loss: 0.0178 Acc: 0.7804\n",
      "test Loss: 0.0245 Acc: 0.7211\n",
      "Epoch 52/75\n",
      "\n",
      "train Loss: 0.0176 Acc: 0.7868\n",
      "test Loss: 0.0233 Acc: 0.7211\n",
      "Epoch 53/75\n",
      "\n",
      "train Loss: 0.0178 Acc: 0.7814\n",
      "test Loss: 0.0240 Acc: 0.7294\n",
      "Epoch 54/75\n",
      "\n",
      "train Loss: 0.0177 Acc: 0.7839\n",
      "test Loss: 0.0241 Acc: 0.7102\n",
      "Epoch 55/75\n",
      "\n",
      "train Loss: 0.0169 Acc: 0.7964\n",
      "test Loss: 0.0244 Acc: 0.7166\n",
      "Epoch 56/75\n",
      "\n",
      "train Loss: 0.0169 Acc: 0.7952\n",
      "test Loss: 0.0244 Acc: 0.7190\n",
      "Epoch 57/75\n",
      "\n",
      "train Loss: 0.0168 Acc: 0.7968\n",
      "test Loss: 0.0240 Acc: 0.7274\n",
      "Epoch 58/75\n",
      "\n",
      "train Loss: 0.0163 Acc: 0.7999\n",
      "test Loss: 0.0238 Acc: 0.7399\n",
      "Epoch 59/75\n",
      "\n",
      "train Loss: 0.0161 Acc: 0.8038\n",
      "test Loss: 0.0244 Acc: 0.7205\n",
      "Epoch 60/75\n",
      "\n",
      "train Loss: 0.0153 Acc: 0.8166\n",
      "test Loss: 0.0241 Acc: 0.7278\n",
      "Epoch 61/75\n",
      "\n",
      "train Loss: 0.0150 Acc: 0.8184\n",
      "test Loss: 0.0242 Acc: 0.7296\n",
      "Epoch 62/75\n",
      "\n",
      "train Loss: 0.0148 Acc: 0.8179\n",
      "test Loss: 0.0232 Acc: 0.7337\n",
      "Epoch 63/75\n",
      "\n",
      "train Loss: 0.0145 Acc: 0.8237\n",
      "test Loss: 0.0244 Acc: 0.7248\n",
      "Epoch 64/75\n",
      "\n",
      "train Loss: 0.0142 Acc: 0.8275\n",
      "test Loss: 0.0266 Acc: 0.6994\n",
      "Epoch 65/75\n",
      "\n",
      "train Loss: 0.0141 Acc: 0.8285\n",
      "test Loss: 0.0234 Acc: 0.7281\n",
      "Epoch 66/75\n",
      "\n",
      "train Loss: 0.0138 Acc: 0.8334\n",
      "test Loss: 0.0225 Acc: 0.7488\n",
      "Epoch 67/75\n",
      "\n",
      "train Loss: 0.0135 Acc: 0.8354\n",
      "test Loss: 0.0248 Acc: 0.7350\n",
      "Epoch 68/75\n",
      "\n",
      "train Loss: 0.0135 Acc: 0.8378\n",
      "test Loss: 0.0248 Acc: 0.7328\n",
      "Epoch 69/75\n",
      "\n",
      "train Loss: 0.0126 Acc: 0.8480\n",
      "test Loss: 0.0259 Acc: 0.7240\n",
      "Epoch 70/75\n",
      "\n",
      "train Loss: 0.0127 Acc: 0.8478\n",
      "test Loss: 0.0261 Acc: 0.7272\n",
      "Epoch 71/75\n",
      "\n",
      "train Loss: 0.0126 Acc: 0.8462\n",
      "test Loss: 0.0236 Acc: 0.7444\n",
      "Epoch 72/75\n",
      "\n",
      "train Loss: 0.0122 Acc: 0.8537\n",
      "test Loss: 0.0265 Acc: 0.7289\n",
      "Epoch 73/75\n",
      "\n",
      "train Loss: 0.0125 Acc: 0.8489\n",
      "test Loss: 0.0247 Acc: 0.7459\n",
      "Epoch 74/75\n",
      "\n",
      "train Loss: 0.0119 Acc: 0.8568\n",
      "test Loss: 0.0234 Acc: 0.7425\n",
      "Epoch 75/75\n",
      "\n",
      "train Loss: 0.0121 Acc: 0.8551\n",
      "test Loss: 0.0253 Acc: 0.7272\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, (num_epochs+1)):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print()\n",
    "    train_expression_model(expression_model, train_loader, loss_fn, optimizer)\n",
    "    test_expression_model(expression_model, test_loader, loss_fn)\n",
    "    scheduler.step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End of VGG Model\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "462459bc3e617147c8cffc282d893ee434b18ff4bde70f08c233dfc73bb28fd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
